[project]
name = "llama-pajamas-run-onnx"
version = "0.1.0"
description = "ONNX Runtime for llama-pajamas with CoreML/TensorRT/CPU support"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "onnxruntime>=1.17.0",
    "numpy>=1.24.0",
]

[project.optional-dependencies]
coreml = [
    "onnxruntime>=1.17.0",  # CoreML EP included on Mac
]
tensorrt = [
    "onnxruntime-gpu>=1.17.0",  # Includes TensorRT EP
]
cuda = [
    "onnxruntime-gpu>=1.17.0",
]

[project.scripts]
llama-pajamas-run-onnx = "llama_pajamas_run_onnx.cli:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
