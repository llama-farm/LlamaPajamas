"""CoreML Speech-to-Text (STT) backend for Apple Silicon.

Supports:
- Whisper models (tiny, base, small, medium, large)
- Streaming transcription
- Multilingual support

Optimized for Apple Neural Engine (ANE).
"""

import logging
from pathlib import Path
from typing import List, Optional, Iterator, Any
import numpy as np

from llama_pajamas_run_core.backends import (
    STTBackend,
    TranscriptionResult,
    TranscriptionSegment,
)

logger = logging.getLogger(__name__)


class CoreMLSTTBackend(STTBackend):
    """CoreML implementation of STT (Speech-to-Text) backend.

    Uses Whisper or similar models converted to CoreML.
    """

    def __init__(self):
        """Initialize CoreML STT backend."""
        self.model = None
        self._model_path: Optional[Path] = None
        self._sample_rate: int = 16000

        # Check CoreML availability
        try:
            import coremltools as ct  # noqa: F401
        except ImportError:
            raise RuntimeError(
                "coremltools not installed. Install with: "
                "pip install coremltools or uv add coremltools"
            )

    def load_model(self, model_path: str, **kwargs) -> None:
        """Load CoreML STT model.

        Args:
            model_path: Path to .mlpackage or .mlmodel file
            **kwargs:
                - sample_rate: int (default: 16000)
                - language: str (e.g., 'en', 'zh')
        """
        import coremltools as ct

        model_path = Path(model_path)
        if not model_path.exists():
            raise FileNotFoundError(f"Model not found: {model_path}")

        logger.info(f"Loading CoreML STT model: {model_path}")

        self.model = ct.models.MLModel(
            str(model_path),
            compute_units=ct.ComputeUnit.ALL,  # Use ANE when possible
        )

        self._model_path = model_path
        self._sample_rate = kwargs.get("sample_rate", 16000)

        logger.info(f"âœ… CoreML STT model loaded successfully")
        logger.info(f"   Sample rate: {self._sample_rate} Hz")

    def transcribe(
        self,
        audio: np.ndarray,
        sample_rate: int = 16000,
        language: Optional[str] = None,
        **kwargs,
    ) -> TranscriptionResult:
        """Transcribe audio to text.

        TODO: Implement CoreML STT pipeline:
        1. Resample audio if needed
        2. Compute mel spectrogram
        3. Run CoreML inference (encoder + decoder)
        4. Post-process outputs
        5. Return TranscriptionResult with segments
        """
        if not self.is_loaded:
            raise RuntimeError("Model not loaded. Call load_model() first.")

        if audio.dtype != np.float32:
            raise ValueError(f"Audio must be float32, got {audio.dtype}")

        if audio.ndim != 1:
            raise ValueError(f"Audio must be mono (1D), got shape {audio.shape}")

        # TODO: Implement STT pipeline
        raise NotImplementedError("STT transcription not yet implemented")

    def transcribe_streaming(
        self,
        audio_stream: Iterator[np.ndarray],
        sample_rate: int = 16000,
        chunk_duration: float = 10.0,
        **kwargs,
    ) -> Iterator[str]:
        """Streaming transcription.

        TODO: Implement streaming STT pipeline
        """
        if not self.is_loaded:
            raise RuntimeError("Model not loaded. Call load_model() first.")

        # TODO: Implement streaming STT
        raise NotImplementedError("Streaming STT not yet implemented")

    def batch_transcribe(
        self,
        audio_list: List[np.ndarray],
        sample_rate: int = 16000,
        language: Optional[str] = None,
        **kwargs,
    ) -> List[TranscriptionResult]:
        """Batch transcription."""
        return [
            self.transcribe(audio, sample_rate, language, **kwargs)
            for audio in audio_list
        ]

    @property
    def supported_languages(self) -> List[str]:
        """Get list of supported language codes.

        TODO: Load from model metadata or config
        """
        # Common Whisper languages
        return [
            "en",
            "zh",
            "de",
            "es",
            "ru",
            "ko",
            "fr",
            "ja",
            "pt",
            "tr",
            "pl",
            "ca",
            "nl",
            "ar",
            "sv",
            "it",
            "id",
            "hi",
            "fi",
            "vi",
            "he",
            "uk",
            "el",
            "ms",
            "cs",
            "ro",
            "da",
            "hu",
            "ta",
        ]

    def unload(self) -> None:
        """Unload model and free resources."""
        if self.model is not None:
            logger.info(f"Unloading CoreML STT model: {self._model_path}")
            self.model = None
            self._model_path = None

    @property
    def is_loaded(self) -> bool:
        """Check if model is loaded."""
        return self.model is not None
